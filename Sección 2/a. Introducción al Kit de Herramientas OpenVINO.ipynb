{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al Kit de Herramientas de OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenVINO es un set de herramientas desarrollado por Intel y lanzado al mercado a finales del año 2018, la ventaja de este Toolkit es que está sumamente optimizado para dispositivos de sobremesa y portátiles Intel(CPU y GPU), a su vez que la empresa ha lanzado aceleradores neuronales como Unidades de Procesamiento Visual(VPU) o FPGA dedicados para tareas entre ellas de Inteligencia Artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicha librería presume de tener algoritmos, documentación y ejemplos para tareas de nueva generación como visión artificial, reconocimiento de habla, procesamiento natural del lenguaje, sistemas de recomendación y muchos otros. Además el Toolkit es compatible con Redes Neuronales de última generación como las Redes Neuronales Convolucionales(CNN) además de Redes Recurrentes y basadas en atención. Además, tienen mucho soporte a dispositivos de frontera, proveyendo de herramientas para la optimización de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principales ventajas\n",
    "\n",
    "De acuerdo al [Desarrollador de la librería](https://docs.openvinotoolkit.org/latest/index.html), las principales ventajas se pueden definir en:\n",
    "- Habilita la inferencia para modelos de Deep Learning en Dispositivos de Frontera\n",
    "- Soporta ejecución heterogénea en las varias gamas de Dispositivos Intel como CPU, GPUs, Intel Neural Compute Stick 2 y el Acelerador de Visión de INtel con Movidius\n",
    "- Acelera el tiempo de desarrollo desde la idea, al proveer funciones de visiones incluídas y kernel optimizados\n",
    "- Incluye versiones optimizadas de las populares librerías de OpenCV y OpenCL\n",
    "- Posibilidad de conversión de modelos de Deep Learning de las librerías más populares(Tensorflow, Caffe, PyTorch, ONNX, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flujo de trabajo con la librería OpenCV\n",
    "Si bien es cierto, que cada desarrollador es libre para escoger el camino que debe llevar su aplicación, desde Intel recomiendan seguir el siguiente cronograma:\n",
    "### Planeación y configuración del dispositivo\n",
    "- Determinación del ambiente de ejecución y la configuración deseada\n",
    "- Determinar el tipo del modelo y librería a utilizar\n",
    "### Seleccionar un modelo\n",
    "- Evaluar si se necesita utilizar un modelo entrenado o entrenar uno\n",
    "- Evaluar la precisión del modelo y si es necesario, reentrenarlo\n",
    "### Fase de modificaciones\n",
    "- Ejecutar el optimizador de modelos para convertir el Modelo a una Representación Intermedia(IR)\n",
    "- Verificar errores de  compatiblidad o añadir capas pesonalizadas\n",
    "- Una vez convertido el modelo a la IR, ejecutarlo en el Motor de Inferencia de Intel\n",
    "### Afinado del modelo\n",
    "- Establecer métricas de objetivo(Velocidad de preocesamiento o precisión deseada)\n",
    "- En caso de ser necesario, utilizar las herramientas de Intel para optimizar el modelo\n",
    "- Evaluar el uso de aceleradores neuronales o ajustes de código\n",
    "### Lanzamiento\n",
    "- Integrar el modelo final en la aplicación\n",
    "- Empaquetar la aplicación para el desarrollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más información https://docs.openvinotoolkit.org/latest/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
