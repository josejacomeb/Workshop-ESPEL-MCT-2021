{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pautas para la Conversión General de Modelos\n",
    "\n",
    "El optimizador de modelos de OpenVINO tiene un script desarrollado en Python que facilita la conversión de cualquier modelo soportado, si sus dependencias de compatibilidad han sido instaladas como se mencionó en Instalación de los requisitos del optimizador de modelos de Aprendizaje Profundo. El Script está localizado en la siguiente dirección, que se puede cambiar con el siguiente comando:\n",
    "- *Windows*\n",
    "```bash\n",
    "cd C:\\Program Files (x86)\\Intel\\openvino_2021\\deployment_tools\\model_optimizer\\\n",
    "```\n",
    "- *Linux*\n",
    "```bash\n",
    "cd /opt/intel/openvino_2021/deployment_tools/model_optimizer/\n",
    "```\n",
    "Como siempre, primero se debe activar las variables de entorno de OpenVINO\n",
    "- *Windows*\n",
    "```bash\n",
    "\"C:\\Program Files (x86)\\Intel\\openvino_2021\\bin\\setupvars.bat\"\n",
    "```\n",
    "- *Linux*\n",
    "\n",
    "```bash\n",
    "source /opt/intel/openvino_2021/bin/setupvars.sh\n",
    "```\n",
    "\n",
    "## Manejo del Optimizador de Modelos\n",
    "El comando mínimo para iniciar la conversión de modelos es el siguiente:\n",
    "- *Windows*\n",
    "```bash\n",
    "python mo.py --input_model INPUT_MODEL --output_dir <OUTPUT_MODEL_DIR>\n",
    "```\n",
    "- *Linux*\n",
    "```bash\n",
    "python3 mo.py --input_model INPUT_MODEL --output_dir <OUTPUT_MODEL_DIR>\n",
    "```\n",
    "Donde los parámetros *INPUT_MODEL* representa la ruta hacia el archivo del modelo de entrada y el *<OUTPUT_MODEL_DIR>* representa la ruta donde guardaremos el Modelo, en los siguientes ejemplos se verá más a profundidad este tema.\n",
    "\n",
    "## Parámetros de Conversión\n",
    "El optimizador de Modelos contiene muchas opciones de configuración para convertir los modelos a la Representación Intermedia(IR), cada modelo y framework tiene sus opciones individuales, aunque no se verá a profundidad esto, a continuación se presenta la lista de parámetros disponibles. \n",
    "\n",
    "```bash\n",
    "content_copy\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --framework {tf,caffe,mxnet,kaldi,onnx}\n",
    "                        Name of the framework used to train the input model.\n",
    " \n",
    "Framework-agnostic parameters:\n",
    "  --input_model INPUT_MODEL, -w INPUT_MODEL, -m INPUT_MODEL\n",
    "                        Tensorflow*: a file with a pre-trained model (binary\n",
    "                        or text .pb file after freezing). Caffe*: a model\n",
    "                        proto file with model weights\n",
    "  --model_name MODEL_NAME, -n MODEL_NAME\n",
    "                        Model_name parameter passed to the final create_ir\n",
    "                        transform. This parameter is used to name a network in\n",
    "                        a generated IR and output .xml/.bin files.\n",
    "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
    "                        Directory that stores the generated IR. By default, it\n",
    "                        is the directory from where the Model Optimizer is\n",
    "                        launched.\n",
    "  --input_shape INPUT_SHAPE\n",
    "                        Input shape(s) that should be fed to an input node(s)\n",
    "                        of the model. Shape is defined as a comma-separated\n",
    "                        list of integer numbers enclosed in parentheses or\n",
    "                        square brackets, for example [1,3,227,227] or\n",
    "                        (1,227,227,3), where the order of dimensions depends\n",
    "                        on the framework input layout of the model. For\n",
    "                        example, [N,C,H,W] is used for Caffe* models and\n",
    "                        [N,H,W,C] for TensorFlow* models. Model Optimizer\n",
    "                        performs necessary transformations to convert the\n",
    "                        shape to the layout required by Inference Engine\n",
    "                        (N,C,H,W). The shape should not contain undefined\n",
    "                        dimensions (? or -1) and should fit the dimensions\n",
    "                        defined in the input operation of the graph. If there\n",
    "                        are multiple inputs in the model, --input_shape should\n",
    "                        contain definition of shape for each input separated\n",
    "                        by a comma, for example: [1,3,227,227],[2,4] for a\n",
    "                        model with two inputs with 4D and 2D shapes.\n",
    "                        Alternatively, specify shapes with the --input\n",
    "                        option.\n",
    "  --scale SCALE, -s SCALE\n",
    "                        All input values coming from original network inputs\n",
    "                        will be divided by this value. When a list of inputs\n",
    "                        is overridden by the --input parameter, this scale is\n",
    "                        not applied for any input that does not match with the\n",
    "                        original input of the model.\n",
    "  --reverse_input_channels\n",
    "                        Switch the input channels order from RGB to BGR (or\n",
    "                        vice versa). Applied to original inputs of the model\n",
    "                        if and only if a number of channels equals 3. Applied\n",
    "                        after application of --mean_values and --scale_values\n",
    "                        options, so numbers in --mean_values and\n",
    "                        --scale_values go in the order of channels used in the\n",
    "                        original model.\n",
    "  --log_level {CRITICAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}\n",
    "                        Logger level\n",
    "  --input INPUT         Quoted list of comma-separated input nodes names with\n",
    "                        shapes, data types, and values for freezing. The shape\n",
    "                        and value are specified as space-separated lists. The\n",
    "                        data type of input node is specified in braces and can\n",
    "                        have one of the values: f64 (float64), f32 (float32),\n",
    "                        f16 (float16), i64 (int64), i32 (int32), u8 (uint8),\n",
    "                        boolean. For example, use the following format to set\n",
    "                        input port 0 of the node `node_name1` with the shape\n",
    "                        [3 4] as an input node and freeze output port 1 of the\n",
    "                        node `node_name2` with the value [20 15] of the int32\n",
    "                        type and shape [2]: \"0:node_name1[3\n",
    "                        4],node_name2:1[2]{i32}->[20 15]\".\n",
    "  --output OUTPUT       The name of the output operation of the model. For\n",
    "                        TensorFlow*, do not add :0 to this name.\n",
    "  --mean_values MEAN_VALUES, -ms MEAN_VALUES\n",
    "                        Mean values to be used for the input image per\n",
    "                        channel. Values to be provided in the (R,G,B) or\n",
    "                        [R,G,B] format. Can be defined for desired input of\n",
    "                        the model, for example: \"--mean_values\n",
    "                        data[255,255,255],info[255,255,255]\". The exact\n",
    "                        meaning and order of channels depend on how the\n",
    "                        original model was trained.\n",
    "  --scale_values SCALE_VALUES\n",
    "                        Scale values to be used for the input image per\n",
    "                        channel. Values are provided in the (R,G,B) or [R,G,B]\n",
    "                        format. Can be defined for desired input of the model,\n",
    "                        for example: \"--scale_values\n",
    "                        data[255,255,255],info[255,255,255]\". The exact\n",
    "                        meaning and order of channels depend on how the\n",
    "                        original model was trained.\n",
    "  --data_type {FP16,FP32,half,float}\n",
    "                        Data type for all intermediate tensors and weights. If\n",
    "                        original model is in FP32 and --data_type=FP16 is\n",
    "                        specified, all model weights and biases are quantized\n",
    "                        to FP16.\n",
    "  --disable_fusing      Turn off fusing of linear operations to Convolution\n",
    "  --disable_resnet_optimization\n",
    "                        Turn off resnet optimization\n",
    "  --finegrain_fusing FINEGRAIN_FUSING\n",
    "                        Regex for layers/operations that won't be fused.\n",
    "                        Example: --finegrain_fusing Convolution1,.*Scale.*\n",
    "  --disable_gfusing     Turn off fusing of grouped convolutions\n",
    "  --enable_concat_optimization\n",
    "                        Turn on Concat optimization.\n",
    "  --extensions EXTENSIONS\n",
    "                        Directory or a comma separated list of directories\n",
    "                        with extensions. To disable all extensions including\n",
    "                        those that are placed at the default location, pass an\n",
    "                        empty string.\n",
    "  --batch BATCH, -b BATCH\n",
    "                        Input batch size\n",
    "  --version             Version of Model Optimizer\n",
    "  --silent              Prevent any output messages except those that\n",
    "                        correspond to log level equals ERROR, that can be set\n",
    "                        with the following option: --log_level. By default,\n",
    "                        log level is already ERROR.\n",
    "  --freeze_placeholder_with_value FREEZE_PLACEHOLDER_WITH_VALUE\n",
    "                        Replaces input layer with constant node with provided\n",
    "                        value, for example: \"node_name->True\". It will be\n",
    "                        DEPRECATED in future releases. Use --input option to\n",
    "                        specify a value for freezing.\n",
    "  --static_shape        Enables IR generation for fixed input shape (folding\n",
    "                        `ShapeOf` operations and shape-calculating sub-graphs\n",
    "                        to `Constant`). Changing model input shape using\n",
    "                        the Inference Engine API in runtime may fail for such an IR.\n",
    "  --disable_weights_compression\n",
    "                        Disable compression and store weights with original\n",
    "                        precision.\n",
    "  --progress            Enable model conversion progress display.\n",
    "  --stream_output       Switch model conversion progress display to a\n",
    "                        multiline mode.\n",
    "  --transformations_config TRANSFORMATIONS_CONFIG\n",
    "                        Use the configuration file with transformations\n",
    "                        description.\n",
    "```\n",
    "\n",
    "\n",
    "## Referencias\n",
    "- [1] Intel. (2021, Agosto 31). Model Optimizer Developer Guide. Intel. [https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
