{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Introducción al IECore e IENetwork\n",
    "\n",
    "Para poder interactuar con el Motor de Inferencia de Intel(Inference Engine) es necesario utilizar dos clases de Python, que son las siguientes:\n",
    "- `IECore`\n",
    "- `IENetwork`\n",
    "Brevemente, se puede visualizar la forma de integración de OpenVINO en cualquier aplicación, básicamente comprende en los siguientes pasos, iniciando con la inicialización del IECore[1].\n",
    "![IE CORE](https://docs.openvinotoolkit.org/latest/integration_process.png)\n",
    "<div align=\"center\"><b>Fig 1.</b> Pasos de la integración de OpenVINO en una aplicación[1]</div>\n",
    "Ahora, se verá brevemente los por menores de ambas clases.\n",
    "\n",
    "## IECore\n",
    "Este elemento del `IECore`[2] es fundamental para la ejecución del Toolkit OpenVINO, es el puente con el Motor de Inferencia(IE) y permite interactuar con el Hardware, conocer la lista de dispositivos disponibles, activar Plugins de Hardware, consultar la compatibilidad de las capas, etc. Para que poder realizar inferencia, necesita cargar un objeto de tipo `IE Network` que es el siguiente a tratar.\n",
    "\n",
    "\n",
    "## IENetwork\n",
    "Este elemento `IENetwork`[3] es el elemento que inicialmente inicializa nuestro modelo de Deep Learning y lo pasa al elemento del `IECore`, además este elemento permite conocer la configuración de entradas y salidas del modelo, nombre del modelo, entradas, etc. Se verá de mejor forma en el siguiente ejemplo.\n",
    "\n",
    "## Ejemplo\n",
    "\n",
    "### Descargar un modelo Pre-Entrenado con el Model Downloader\n",
    "Para este ejemplo es necesario primero descargar el modelo `person-detection-retail-0013`[4] para detección de peatones. Por favor, **ejecutar** esta celda para descargar el archivo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading person-detection-retail-0013 ||################\n",
      "\n",
      "========== Downloading /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml\n",
      "... 100%, 374 KB, 439 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.bin\n",
      "... 100%, 2823 KB, 485 KB/s, 5 seconds passed\n",
      "\n",
      "========== Downloading /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4/intel/person-detection-retail-0013/FP16/person-detection-retail-0013.xml\n",
      "... 100%, 373 KB, 429 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4/intel/person-detection-retail-0013/FP16/person-detection-retail-0013.bin\n",
      "... 100%, 1411 KB, 431 KB/s, 3 seconds passed\n",
      "\n",
      "========== Downloading /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4/intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.xml\n",
      "... 100%, 948 KB, 467 KB/s, 2 seconds passed\n",
      "\n",
      "========== Downloading /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4/intel/person-detection-retail-0013/FP16-INT8/person-detection-retail-0013.bin\n",
      "... 100%, 752 KB, 463 KB/s, 1 seconds passed\n",
      "\n",
      "Ruta donde se guardó el archivo: /home/josejacomeb/Documents/Workshop-ESPEL-MCT-2021/Sección 4\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "nombre_modelo = \"person-detection-retail-0013\"\n",
    "ruta_archivo = os.getcwd()\n",
    "if sys.platform == \"win32\":\n",
    "    ruta_model_downloader=\"C:\\Program Files (x86)\\Intel\\openvino_2021\\deployment_tools\\tools\\model_downloader\\downloader.py\"\n",
    "    !python {ruta_model_downloader} --name {nombre_modelo}\n",
    "    print(\"Ruta donde se guardó el archivo: {}\".format(ruta_archivo))\n",
    "elif sys.platform == \"linux\":\n",
    "    ruta_model_downloader=\"/opt/intel/openvino_2021/deployment_tools/tools/model_downloader/downloader.py\"\n",
    "    !python {ruta_model_downloader} --name {nombre_modelo}\n",
    "    print(\"Ruta donde se guardó el archivo: {}\".format(ruta_archivo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de la carpeta `intel/person-detection-retail-0013/` se han descargado tres modelos, con varias precisiones(`FP32, FP16, FP16-INT6`), los archivos que nos interesan son los siguientes:\n",
    "- Archivo que contiene los pesos: `intel/person-detection-retail-0013/{Precision}/person-detection-retail-0013.bin`\n",
    "- Archivo que contiene la arquitectura: `intel/person-detection-retail-0013/{Precision}/person-detection-retail-0013.xml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar las variables de entorno de OpenVINO\n",
    "Como siempre, hay que inicializar las variables de entorno de OpenVINO, por favor **ejecutar** la celda correspondiente: \n",
    "- *Windows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cmd\n",
    "\"C:\\Program Files (x86)\\Intel\\openvino_2021\\bin\\setupvars.bat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Linux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /opt/intel/openvino_2021/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar el código de Python\n",
    "En el presente código, vamos a inicializar los objetos de tipo `IECore`[2] y `IENetwork`[3], cargaremos el modelo y obtendremos información básica sobre el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResMobNet_v4 (LReLU) with single SSD head\n"
     ]
    }
   ],
   "source": [
    "#Cargar las clases de IECore, IENetwork\n",
    "from openvino.inference_engine import IECore\n",
    "\n",
    "ruta_modelo_xml = \"intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml\"\n",
    "ruta_modelo_bin = ruta_modelo_xml.split(\".\")[0] + \".bin\" #Cambiar la extensión de modelo a bin \n",
    "\n",
    "core = IECore() #Inicializo el objeto IECore\n",
    "network = core.read_network(model=ruta_modelo_xml, weights=ruta_modelo_bin) #Inicializo el objeto de tipo IENetwork a través de la función core.read_work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** En caso de no poder ejecutar el código anterior, desde el CMD de Windows o Terminal de Linux, primero inicializar las variables de entorno en el terminal y luego ejecutar el Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Obtener información del los dispositivos\n",
    "El siguiente código obtendrá los dispositivos disponibles para hacer inferencia con OpenVINO y la versión de sus plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dispositivos Compatibles OpenVINO en mi Computador ######\n",
      "Hay 4 dispositivos disponibles para realizar la inferencia\n",
      "['CPU', 'GNA', 'GPU', 'MYRIAD']\n",
      "###### Versiones de los Plugins disponibles ######\n",
      "CPU: MKLDNNPlugin build number: 2021.4.0-3839-cd81789d294-releases/2021/4 version: 2_1\n",
      "GNA: GNAPlugin build number: 2021.4.0-3839-cd81789d294-releases/2021/4_with_GNA_LIB_VER==2 version: 2_1\n",
      "GPU: clDNNPlugin build number: 2021.4.0-3839-cd81789d294-releases/2021/4 version: 2_1\n",
      "MYRIAD: myriadPlugin build number: 2021.4.0-3839-cd81789d294-releases/2021/4 version: 2_1\n"
     ]
    }
   ],
   "source": [
    "print(\"{} Dispositivos Compatibles OpenVINO en mi Computador {}\".format(6*\"#\", 6*\"#\"))\n",
    "dispositivos_compatibles = core.available_devices\n",
    "print(\"Hay {} dispositivos disponibles para realizar la inferencia\".format(len(dispositivos_compatibles)))\n",
    "print(dispositivos_compatibles)\n",
    "#Imprimir la versión del plugin del sistema\n",
    "print(\"{} Versiones de los Plugins disponibles {}\".format(6*\"#\", 6*\"#\"))\n",
    "for dispositivo in dispositivos_compatibles:\n",
    "    version = core.get_versions(dispositivo)\n",
    "    descripcion = getattr(version[dispositivo], 'description')\n",
    "    major = getattr(version[dispositivo], 'major')\n",
    "    minor = getattr(version[dispositivo], 'minor')\n",
    "    build_number = getattr(version[dispositivo], 'build_number')\n",
    "    \n",
    "    print(\"{}: {} build number: {} version: {}_{}\".format(dispositivo, descripcion, build_number, major, minor ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, en mi equipo hay cuatro dispositivos compatibles con los que puedo hacer inferencia, y la versión de los pluings es la más actual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Obtener información del modelo de Deep Learning\n",
    "El siguiente código obtendrá los dispositivos disponibles para hacer inferencia con OpenVINO y la versión de sus plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Información del modelo ######\n",
      "Nombre del modelo: ResMobNet_v4 (LReLU) with single SSD head\n",
      "Nombre de la capa de entrada: data\n",
      "Formato de entrada: [1, 3, 320, 544]\n",
      "Nombre de la capa de salida: detection_out\n",
      "Formato de salida: [1, 1, 200, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"{} Información del modelo {}\".format(6*\"#\", 6*\"#\"))\n",
    "print(\"Nombre del modelo: {}\".format(network.name))\n",
    "nombre_capa_entrada = next(iter(network.input_info))\n",
    "print(\"Nombre de la capa de entrada: {}\".format(nombre_capa_entrada))\n",
    "print(\"Formato de entrada: {}\".format(network.input_info[nombre_capa_entrada].input_data.shape))\n",
    "nombre_capa_salida = next(iter(network.outputs))\n",
    "print(\"Nombre de la capa de salida: {}\".format(nombre_capa_salida))\n",
    "print(\"Formato de salida: {}\".format(network.outputs[nombre_capa_salida].shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de la red, nos dan una referencia clara de como utilizar las entradas y las salidas del modelo, para así realizar la inferencia con los datos claros. Según la documentación del modelo `person-detection-retail-0013`[4], se comprobó facilmente que son los datos del modelo, ya que sus datos son según Intel son:: \n",
    "- Capa de Entrada\n",
    "Forma del vector de entrada: `1, 3, 320, 544` en el formato `B, C, H, W`, donde:\n",
    "\n",
    "    - B - Tamaño del Batch\n",
    "    - C - Número de canales\n",
    "    - H - alto de la imagen\n",
    "    - W - ancho de la imagen\n",
    "\n",
    "El order de color es en BGR.\n",
    "- Capa de Salida\n",
    "Forma del vector de salida: `1, 1, 200, 7` en el formato `1, 1, N, 7`, donde `N` es el número de bounding boxes detectadas. Cada detección tiene la forma `[image_id, label, conf, x_min, y_min, x_max, y_max]`, donde:\n",
    "\n",
    "    - image_id - ID de la imagen en el Batch\n",
    "    - label - ID predicción de la clase (1 - persona)\n",
    "    - conf - precisión de la clase preedicha\n",
    "    - (x_min, y_min) - coordenadas de la esquina superior izquierda del bounding box\n",
    "    - (x_max, y_max) - coordenadas de la  esquina inferior derecha del bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- [1] Intel. (2021, Agosto 31).Integrate the Inference Engine with Your Application. Intel. [https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_Integrate_with_customer_application_new_API.html](https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_Integrate_with_customer_application_new_API.html)\n",
    "- [2] Intel. (2021, Agosto 31). ie_api.IECore Class Reference. Intel. [https://docs.openvinotoolkit.org/2021.4/ie_python_api/classie__api_1_1IECore.html](https://docs.openvinotoolkit.org/2021.4/ie_python_api/classie__api_1_1IECore.html)\n",
    "- [3] Intel. (2021, Agosto 31). ie_api.IENetwork Class Reference. Intel. [https://docs.openvinotoolkit.org/2021.4/ie_python_api/classie__api_1_1IENetwork.html](https://docs.openvinotoolkit.org/2021.4/ie_python_api/classie__api_1_1IENetwork.html)\n",
    "- [4] Intel. (2021, Agosto 31). person-detection-retail-0013. Intel. [https://docs.openvinotoolkit.org/latest/omz_models_model_person_detection_retail_0013.html](https://docs.openvinotoolkit.org/latest/omz_models_model_person_detection_retail_0013.html)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
